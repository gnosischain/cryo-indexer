# Cryo Indexer Configuration

# Ethereum RPC endpoint (required for all operations except backfill)
ETH_RPC_URL=https://eth-mainnet.g.alchemy.com/v2/your-key-here

# Network name (default: ethereum)
# Options: ethereum, gnosis, polygon, arbitrum, optimism, etc.
NETWORK_NAME=ethereum

# ClickHouse connection (required)
CLICKHOUSE_HOST=your-clickhouse-host.clickhouse.cloud
CLICKHOUSE_USER=default
CLICKHOUSE_PASSWORD=your-password-here
CLICKHOUSE_DATABASE=blockchain
CLICKHOUSE_PORT=8443
CLICKHOUSE_SECURE=true

# Operation mode (default: continuous)
# Options: continuous, historical, fill_gaps, validate, backfill, fix_timestamps
OPERATION=continuous

# Indexing mode (default: minimal)
# Options: minimal (blocks,transactions,logs), extra (contracts,native_transfers,traces), 
#          diffs (balance_diffs,code_diffs,nonce_diffs,storage_diffs), full (all datasets), custom
MODE=minimal

# Custom datasets (only used when MODE=custom)
# Available: blocks, transactions, logs, contracts, native_transfers, traces, 
#           balance_diffs, code_diffs, nonce_diffs, storage_diffs
# Example: DATASETS=blocks,transactions,logs,traces
DATASETS=

# Block range for historical/fill_gaps/backfill operations
START_BLOCK=0
END_BLOCK=0

# Performance settings
WORKERS=1                    # Number of parallel workers
BATCH_SIZE=1000             # Blocks per batch (historical mode)
MAX_RETRIES=3               # Max retry attempts for failed ranges
REQUESTS_PER_SECOND=50      # RPC requests per second limit
MAX_CONCURRENT_REQUESTS=5    # Max concurrent RPC requests
CRYO_TIMEOUT=300            # Cryo command timeout (seconds)

# Fixed range size for all indexing operations
# This ensures predictable state management and efficient processing
INDEXING_RANGE_SIZE=1000    # Size of each indexing range (default: 1000 blocks)

# Continuous mode settings
CONFIRMATION_BLOCKS=12       # Blocks to wait before indexing (reorg protection)
POLL_INTERVAL=10            # Seconds between chain tip checks

# Backfill settings
BACKFILL_CHUNK_SIZE=100000  # Size of chunks for scanning tables (memory efficiency)
BACKFILL_FORCE=false        # Force recreation of existing entries (use with caution)

# Gap detection settings
GAP_DETECTION_STATE_CHUNK_SIZE=100000    # Chunk size for state-based gap detection
GAP_DETECTION_TABLE_CHUNK_SIZE=10000     # Chunk size for table-based gap detection
GAP_DETECTION_THRESHOLD=0.8              # Threshold (0.0-1.0) for switching to table-based detection
                                         # 0.8 means: if 80%+ ranges appear as gaps, verify with actual table data

# Timestamp Fix Settings
TIMESTAMP_FIX_BATCH_SIZE=100000          # Batch size for fixing timestamps
STRICT_TIMESTAMP_MODE=false              # Fail if blocks aren't available for timestamps

# Stale Job Detection
STALE_JOB_TIMEOUT_MINUTES=30             # Minutes before a 'processing' job is considered stale
                                         # Prevents stuck ranges when indexer crashes/restarts

# Enhanced gap filling settings
HANDLE_FAILED_RANGES=false               # Also reprocess failed ranges during fill-gaps
DELETE_FAILED_BEFORE_RETRY=false         # Delete failed entries before retrying
MAX_RETRIES_OVERRIDE=0                   # Override MAX_RETRIES for fill-gaps (0 = use MAX_RETRIES)

# Deduplication settings (Delete Before Insert strategy)
DELETE_BEFORE_REPROCESS=true             # Delete existing data before reprocessing ranges
DELETION_WAIT_TIME=1.0                   # Seconds to wait after deletion for propagation

# Resource limits (Docker)
MEMORY_LIMIT=4G             # Maximum memory for container
CPU_LIMIT=2                 # Maximum CPU cores
MEMORY_RESERVATION=2G       # Reserved memory
CPU_RESERVATION=1           # Reserved CPU cores

# Logging
LOG_LEVEL=INFO              # Options: DEBUG, INFO, WARNING, ERROR

# Restart policy (Docker)
RESTART_POLICY=unless-stopped  # Options: no, always, unless-stopped, on-failure